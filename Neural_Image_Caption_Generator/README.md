# Show and tell - Neural Image Caption Generator
This project is to reimplement the show and tell paper (Vinyals et al., 2015). This application helps visually-impaired people by transforming visual signals into proper language, which involves tasks of both image classification as well as natural language processing. Using 500 GPU hours for training, we managed to improve the performance and the convergence by replacing the pre-trained model to ResNet 152, using Adam optimizer and several other experiments. As a result, the model yields better performance compared to the original paper on the MSCOCO 2014 testing set.

## Implementation

## Results
